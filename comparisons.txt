
Stanford NER 
CRFClassifier tagged 156234 words in 7194 documents at 6861.70 words per second.
Entity    P       R       F1      TP      FP      FN
    art    0.3333  0.1364  0.1935  9       18      57
    eve    0.4000  0.2703  0.3226  10      15      27
    geo    0.8523  0.8958  0.8735  4987    864     580
    gpe    0.9590  0.9478  0.9534  2362    101     130
    nat    0.5600  0.4242  0.4828  14      11      19
    org    0.7519  0.7077  0.7291  2164    714     894
    per    0.7804  0.7559  0.7679  1873    527     605
    tim    0.9172  0.8670  0.8914  2692    243     413
Totals    0.8499  0.8381  0.8440  14111   2493    2725

BERT NER - bert-base-cased
01/14/2020 23:13:27 - INFO - __main__ -   ***** Eval results  *****
01/14/2020 23:13:27 - INFO - __main__ -     f1 = 0.844596588561648
01/14/2020 23:13:27 - INFO - __main__ -     loss = 0.09425627291202546
01/14/2020 23:13:27 - INFO - __main__ -     precision = 0.8392961876832845
01/14/2020 23:13:27 - INFO - __main__ -     recall = 0.8499643620812545

BERT NER - bert-large-cased
01/15/2020 02:01:40 - INFO - __main__ -   ***** Eval results  *****
01/15/2020 02:01:40 - INFO - __main__ -     f1 = 0.843384869585743
01/15/2020 02:01:40 - INFO - __main__ -     loss = 0.09949652567609317
01/15/2020 02:01:40 - INFO - __main__ -     precision = 0.8379455909943715
01/15/2020 02:01:40 - INFO - __main__ -     recall = 0.8488952245188881


# Bi-LSTM  CRF removing art 
Evaluation on test set
Accuracy: 0.9618
F1 score: 0.7995
           precision    recall  f1-score   support

      geo       0.81      0.87      0.84      5567
      org       0.68      0.61      0.64      3058
      gpe       0.97      0.93      0.95      2492
      tim       0.85      0.82      0.84      3105
      per       0.75      0.65      0.70      2478
      nat       0.41      0.21      0.28        33
      eve       0.18      0.08      0.11        37

micro avg       0.81      0.79      0.80     16770
macro avg       0.81      0.79      0.80     16770

# Bi-LSTM CRF on popular classes Evaluation on test set
Accuracy: 0.9615
F1 score: 0.7969
           precision    recall  f1-score   support

      geo       0.82      0.87      0.85      5567
      tim       0.84      0.82      0.83      3105
      per       0.69      0.69      0.69      2478
      org       0.70      0.59      0.64      3058
      gpe       0.96      0.94      0.95      2492
      art       0.00      0.00      0.00        66
      nat       0.00      0.00      0.00        33
      eve       0.00      0.00      0.00        37

micro avg       0.81      0.79      0.80     16836
macro avg       0.80      0.79      0.79     16836

# Boundary detection 
Evaluation on test set
Accuracy: 0.9737
F1 score: 0.8619
           precision    recall  f1-score   support

   entity       0.87      0.86      0.86     16836

micro avg       0.87      0.86      0.86     16836
macro avg       0.87      0.86      0.86     16836
